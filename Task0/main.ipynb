{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import torch\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vision_transformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "import torch.nn.functional as F\n",
    "from pytorch_pretrained_vit import ViT\n",
    "from timm import create_model\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281\n"
     ]
    }
   ],
   "source": [
    "path = '../../objrecognition/objrecognition/norm'\n",
    "\n",
    "files = os.listdir(path)\n",
    "dataset = []\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(path, file)\n",
    "    if os.path.isdir(file_path):\n",
    "        images = os.listdir(file_path)\n",
    "        for image in images:\n",
    "            img = Image.open(os.path.join(file_path, image))\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.copy()\n",
    "            dataset.append([img, int(file.split()[0][1])])\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "140\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(dataset)\n",
    "train_dataset = dataset[0:1001]\n",
    "val_dataset = dataset[1001:1141]\n",
    "test_dataset = dataset[1141:1281]\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_x = []\n",
    "train_dataset_y = []\n",
    "val_dataset_x = []\n",
    "val_dataset_y = []\n",
    "test_dataset_x = []\n",
    "test_dataset_y = []\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    train_dataset_x.append(train_dataset[i][0])\n",
    "    train_dataset_y.append(train_dataset[i][1])\n",
    "for i in range(len(val_dataset)):\n",
    "    val_dataset_x.append(val_dataset[i][0])\n",
    "    val_dataset_y.append(val_dataset[i][1])\n",
    "for i in range(len(test_dataset)):\n",
    "    test_dataset_x.append(test_dataset[i][0])\n",
    "    test_dataset_y.append(test_dataset[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, img_transform):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.img_transform = img_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        sample = self.img_transform(sample)\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_dataset_x, train_dataset_y, transform)\n",
    "val_dataset = CustomDataset(val_dataset_x, val_dataset_y, transform)\n",
    "test_dataset = CustomDataset(test_dataset_x, test_dataset_y, transform)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:55<00:00,  9.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = create_model('vit_base_patch16_224', pretrained=True)\n",
    "num_features = model.head.in_features\n",
    "model.head = nn.Linear(num_features, 3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "total_accuracy = 0.0\n",
    "total_samples = 0\n",
    "for inputs, labels in val_dataloader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    predictions = F.softmax(outputs, dim=-1)\n",
    "    predicted_classes = torch.argmax(predictions, dim=-1)\n",
    "    accuracy = (predicted_classes == labels).float().mean()\n",
    "    total_accuracy += accuracy.item() * inputs.size(0)\n",
    "    total_samples += inputs.size(0)\n",
    "\n",
    "print(\"Validation Accuracy:\", total_accuracy / total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m val_dataloader\n\u001b[0;32m      5\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for inputs, labels in val_dataloader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "    # Преобразуем тензоры меток в numpy массивы\n",
    "    real_labels = labels.cpu().numpy()\n",
    "    predicted_labels = predictions.cpu().numpy()\n",
    "\n",
    "    # Добавляем метки в соответствующие списки\n",
    "    real_labels_list.extend(real_labels)\n",
    "    predicted_labels_list.extend(predicted_labels)\n",
    "\n",
    "    # Показываем изображения\n",
    "    for i in range(inputs.size(0)):\n",
    "        img = inputs[i].permute(1, 2, 0).cpu().numpy()  # Переводим тензор изображения в массив numpy\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Real: {class_names[real_labels[i]]}, Predicted: {class_names[predicted_labels[i]]}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
